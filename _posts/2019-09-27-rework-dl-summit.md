---
layout: post
title: RE•WORK DL Summit Wrapup and Reading List
author: Twin Karmakharm
slug: 2019-09-27-rework-dl-summit
date: 2019-09-27 17:00:00 UTC
tags:
category:
link:
description:
type: text
---

## Conference Summary

I’m back at the [RE•WORK DL summit](https://www.re-work.co/events/deep-learning-summit-london-2019) again this year to catch up with some of the hottest research in Deep Learning (DL). I've shared a reading list at the end of this article that is related to the main track sessions I attended.

Of particular interest to me was a talk by [Richard Turner](http://www.eng.cam.ac.uk/profiles/ret26) that uses [adaptive networks](https://arxiv.org/abs/1906.07697) to allow continuous training with new data instead of having to re-train from scratch.

Reinforcement Learning was heavily featured this time as researchers coax DL algorithms to paint, control robots, drive, and play starcraft. There was also a variety of talks related to autonomous driving that range from making sense of sensor data to controlling the car itself. 

In the talks, the problem of data inefficiency is an issue that came up often, for example Alphastar AI agents are trained for over 200 gaming years to be able to compete with the best players. Another important issue that remains unsolved, especially for safty critical systems, is how to ensure that the algorithms behave sensibly in all situations, even in the rare cases where there's little or no available training data. 

[Prof. Neil Lawrance's](http://inverseprobability.com) talk on [Machine Learning Systems Design](http://inverseprobability.com/2018/11/05/the-3ds-of-machine-learning-systems-design) highlights these problems, stating that we're experiencing a 'data crisis'. In reference to [Edsger Dijkstra's Software crisis](https://en.wikipedia.org/wiki/Software_crisis) whereby software gets more complex (and more expensive) in tandem with compute power, now that software is generated by data, more and more effort needs to be spent to improving and verifying the dataset. In addition to incrased focus on data, it is also important to ensure tracability of training process and that deployed systems are constantly monitored to detect anomalous inputs and outputs.

The conference ended with a panel talk on AI explainability. Now that transparency of decision made by AI is required by UK's GDPR law, companies need to start actively work on explaining their algorithms. The panel has a consensus that, yes it's an important issue and the industry is working on improving their practices. There was a suggestion for exploring the use simpler models first (e.g. regression, decision trees) where it is easier to explain the correlation between inputs and prediction. More details can be found in ICO's [interim report on AI explainability](https://ico.org.uk/about-the-ico/research-and-reports/project-explain-interim-report/) which is definitely worth a read.

## Reading List & Resource

Below is a list of reading materials and resources that came up in the conference:

* AI Explainability
	* [ICO interim report on AI explainability](https://ico.org.uk/about-the-ico/research-and-reports/project-explain-interim-report/)
* Autonomous Driving
	* Sensors
		* [Driven to Distraction: Self-Supervised Distractor Learning for Robust Monocular Visual Odometry in Urban Environments](https://ieeexplore.ieee.org/abstract/document/8460564)
		* [Probably Unknown: Deep Inverse Sensor Modelling In Radar](https://arxiv.org/abs/1810.08151)
		* [Masking by Moving: Learning Distraction-Free Radar Odometry from Pose Information](https://arxiv.org/abs/1909.03752)
		* [PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation](https://arxiv.org/abs/1612.00593)
	* End-to-end algorithm
		* [Learning to Drive in a Day](https://arxiv.org/abs/1807.00412)
			* [SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation](https://arxiv.org/abs/1511.00561)
			* [Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics](https://arxiv.org/abs/1705.07115)
		* [Learning to Drive from Simulation without Real World Labels](https://arxiv.org/abs/1812.03823)
	* Dataset
		* [Oxford Robotcar Dataset](https://robotcar-dataset.robots.ox.ac.uk/)
		* [Waymo Open Dataset](https://waymo.com/open/)
		* [NUSCENES (Aptiv) Dataset](https://www.nuscenes.org/)
		* [Lyft Dataset](https://level5.lyft.com/dataset/)
		* [PandaSet](https://scale.com/open-datasets/pandaset)
		* [KITTI](http://www.cvlibs.net/datasets/kitti/)
* Computer Vision
	* 3D Perception of Human Appearance and Geometry in the Wild
		* [Panoptic Segmentation](https://arxiv.org/abs/1801.00868)
		* [Learning Category-Specific Mesh Reconstruction from Image Collections](https://arxiv.org/abs/1803.07549)
		* [SMPL: A Skinned Multi-Person Linear Model](http://smpl.is.tue.mpg.de/)
		* [DensePose: Dense Human Pose Estimation In The Wild](https://arxiv.org/abs/1802.00434)
	* Augmented Intelligence for Cardiovascular Imaging and Analysis
		* [Evaluation of Algorithms for Multi-Modality Whole Heart Segmentation: An Open-Access Grand Challenge](https://arxiv.org/abs/1902.07880)
		* [Left Atrium Fibrosis and Scar Segmentation Challenge](http://www.cardiacatlas.org/challenges/left-atrium-fibrosis-and-scar-segmentation-challenge/)
	* Deep Learning for Space Exploration
		* [DeepTerramechanics: Terrain Classification and Slip Estimation for Ground Robots via Deep Learning](https://arxiv.org/abs/1806.07379)
		* [SPOC: Deep Learning-based Terrain Classification for Mars Rover Missions](https://doi.org/10.2514/6.2016-5539)
		* [Mars 2020 mission website](https://mars.nasa.gov/mars2020/)
* Continuous training, transfer learning
	* [Fast and Flexible Multi-Task Classification Using Conditional Neural Adaptive Processes](https://arxiv.org/abs/1906.07697)
	* [Meta-Dataset: A Dataset of Datasets for Learning to Learn from Few Examples](https://arxiv.org/abs/1903.03096)
* Natural Language
	* Grounded Language: Answering Questions about Images and Navigation with Instructions
		* [Learning to Understand Goal Specifications by Modelling Reward](https://arxiv.org/abs/1806.01946)
		* [Grounded Language Learning in a Simulated 3D World](https://arxiv.org/abs/1706.06551)
		* [A Multi-World Approach to Question Answering about Real-World Scenes based on Uncertain Input](https://arxiv.org/abs/1410.0210)
		* [CLEVR: A Diagnostic Dataset for 
		Compositional Language and Elementary Visual Reasoning](https://cs.stanford.edu/people/jcjohns/clevr/)
		* [A neural approach to relational reasoning](https://deepmind.com/blog/article/neural-approach-relational-reasoning)
		* [Learning Visual Question Answering by Bootstrapping Hard Attention](https://arxiv.org/abs/1808.00300)
		* [Learning To Follow Directions in Street View](https://arxiv.org/abs/1903.00401)
		* [Differentiable neural computers](https://deepmind.com/blog/article/differentiable-neural-computers)
	* [PELTARION](https://peltarion.com/) uses BERT to perform sentence similarity analysis on their marketing question in order to reduce the number of possible questions 
		* [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)
		* [XLNet: Generalized Autoregressive Pretraining for Language Understanding](https://arxiv.org/abs/1906.08237)
		* [RoBERTa: A Robustly Optimized BERT Pretraining Approach](https://arxiv.org/abs/1907.11692)
* Reinforcement Learning
	* [Alphastar: Deepmind's article on training Deep RL networks to play Starcraft](https://deepmind.com/blog/article/alphastar-mastering-real-time-strategy-game-starcraft-ii)
	* Humans providing corrective advice to train robit motor skills
		* [Reinforcement Learning of Motor Skills using Policy Search and Human Corrective Advice](https://www.ias.informatik.tu-darmstadt.de/uploads/Alumni/JensKober/IJRR__Revision_.pdf)
	* [Learning to write programs that generate images (Deepmind blog article)](https://deepmind.com/blog/article/learning-to-generate-images)
	* Microsoft Reserach using minecraft to experient with AI 
		* [Project malmo website](https://aka.ms/project-malmo)
		* [Github page](github.com/microsoft/malmo)
		* [MS Reserach Game intelligence page](aka.ms/gameintelligence)
		* [MineRL competition](https://minerl.io/competition)
	* Self-supervising, automatic goal generation, learning algorithms
		* [Intrinsically Motivated Goal Exploration Processes with Automatic Curriculum Learning](https://arxiv.org/abs/1708.02190)
		* [Computational Theories of Curiosity-Driven Learning](https://arxiv.org/abs/1802.10546)
* Time series anomaly detection
	* LSTM
		* [LSTM-based Encoder-Decoder for Multi-sensor Anomaly Detection](https://arxiv.org/abs/1607.00148)
		* [Detecting Spacecraft Anomalies Using LSTMs and Nonparametric Dynamic Thresholding (This is what Airbus used to do their anomaly detection)](https://arxiv.org/abs/1802.04431)
	* CNN
		* [DeepAnT: A Deep Learning Approach for Unsupervised Anomaly Detection in Time Series](https://ieeexplore.ieee.org/abstract/document/8581424)
	* Autoencoder
		* [Diagnostics for conformity of paired quantitative measurements](https://doi.org/10.1002/sim.1013)
		* [Robust Anomaly Detection for Multivariate Time Series through Stochastic Recurrent Neural Network](https://doi.org/10.1145/3292500.3330672)
	* GANs
		* [Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide Marker Discovery](https://link.springer.com/chapter/10.1007/978-3-319-59050-9_12)
		* [MAD-GAN: Multivariate Anomaly Detection for Time Series Data with Generative Adversarial Networks](https://arxiv.org/abs/1901.04997)
	* [Airbus AI Gym Challenge](https://aigym.airbus.com)
