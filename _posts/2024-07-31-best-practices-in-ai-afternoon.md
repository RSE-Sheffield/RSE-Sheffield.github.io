---
layout: post
title: "Best Practices in AI Afternoon Event Summary"
author: Twin Karmakharm and Christopher Wild
slug: 2024-07-31-best-practices-in-ai-afternoon-event-summary
date: 2024-07-31 09:00:00 UTC
tags: AI LLM Docker Testing
category:
link:
description:
social_image:
type: text
excerpt_separator: <!--more-->
---

<div style="margin-top: 1em; margin-bottom: 1em;">
<img src="/assets/images/2024-07-05-best-practices-in-ai/banner-gforms.svg" alt="Best Practices in AI Afternoon Banner"/>
</div>

We've finally put all the videos, slides and other resources together from the [Best Practices in AI Afternoon](/events/seminar-2024-07-05-best-practices-in-ai-afternoon) 
event that happened on the 5th of July 2024. You can find them listed below.
  

### Maximizing Efficiency in Large Language Models: Compute, Memory, and Fine-Tuning
**<img class="align-self-center mr-2" src="/assets/images/icons/icons8-communication-skill-50.png" width="20" alt="Speaker"> Karin Sevegnani, Senior Solutions Architect, Nvidia**

In this talk, we will explore the intricate balance between computational resources, memory limitations, and parameter-efficient fine-tuning techniques in large language models (LLMs). We will analyse strategies to optimize the performance of LLMs while managing these constraints effectively. From efficient memory utilization to streamlined parameter fine-tuning methods, we will discuss practical approaches to maximize the efficiency of LLMs without sacrificing performance.

<iframe id="kaltura_player" type="text/javascript"  src='https://cdnapisec.kaltura.com/p/2103181/embedPlaykitJs/uiconf_id/53345422?iframeembed=true&entry_id=1_3uimk13k&config[provider]={"widgetId":"1_08d7ws2x"}&config[playback]={"startTime":0}'  style="width: 400px;height: 285px;border: 0;" allowfullscreen webkitallowfullscreen mozAllowFullScreen allow="autoplay *; fullscreen *; encrypted-media *" sandbox="allow-downloads allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation" title="Maximizing Efficiency in Large Language Models: Compute, Memory, and Fine-Tuning"></iframe>

- [Presentation slides](https://nvidia-gpugenius.highspot.com/viewer/668bacf0b742e161aab7e95c?iid=6688069f3f35f83f5dd60161)

### Docker for Machine Learning
**<img class="align-self-center mr-2" src="/assets/images/icons/icons8-communication-skill-50.png" width="20" alt="Speaker"> Ryan Daniels, University of Cambridge**

Writing research software in Python presents numerous challenges to reproducibility - what version of Python is being used? What about the versions of PyTorch, Scikit Learn or Numpy? Should we use Conda, or venv, or Poetry to manage dependencies and environments? How can we control randomness? Do I have the right version of Cuda Toolkit? In principle, given the same data, and same algorithms and methodology, we should be able to reproduce the results of any given experiment to within an acceptable degree of error. Dealing with the above questions introduces significant problems to reproducing experiments in machine learning. In this talk, I would like to convince you that Docker can help alleviate almost all of these questions. Furthermore, combining Docker, git and GitHub can be a powerful workflow, helping to minimise your tech stack, and declutter your python development experience.

<iframe id="kaltura_player" type="text/javascript"  src='https://cdnapisec.kaltura.com/p/2103181/embedPlaykitJs/uiconf_id/53345422?iframeembed=true&entry_id=1_ea910iqv&config[provider]={"widgetId":"1_foxtxokg"}&config[playback]={"startTime":0}'  style="width: 400px;height: 285px;border: 0;" allowfullscreen webkitallowfullscreen mozAllowFullScreen allow="autoplay *; fullscreen *; encrypted-media *" sandbox="allow-downloads allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation" title="Docker for Research Software"></iframe>

- [Presentation slides](/assets/slides/2024-07-05-best-practices-ai/docker_for_rse.pdf)

### How do you unit test an ML model?
**<img class="align-self-center mr-2" src="/assets/images/icons/icons8-communication-skill-50.png" width="20" alt="Speaker"> Wahab Kawafi, University of Bristol**

Covering methods such as mock testing, simulation, experiment tracking, and dataset curation. With examples in medicine, chemistry, aerospace engineering, and LLMs.

<iframe id="kaltura_player" type="text/javascript"  src='https://cdnapisec.kaltura.com/p/2103181/embedPlaykitJs/uiconf_id/53345422?iframeembed=true&entry_id=1_2yuxckko&config[provider]={"widgetId":"1_b9fcv3r6"}&config[playback]={"startTime":0}'  style="width: 400px;height: 285px;border: 0;" allowfullscreen webkitallowfullscreen mozAllowFullScreen allow="autoplay *; fullscreen *; encrypted-media *" sandbox="allow-downloads allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation" title="How do you unit test an ML model?"></iframe>

- [Presentation slides](/assets/slides/2024-07-05-best-practices-ai/unit_test_ml_model.pdf)

### How to make your machine learning code faster
**<img class="align-self-center mr-2" src="/assets/images/icons/icons8-communication-skill-50.png" width="20" alt="Speaker"> Edwin Brown, Research Software Engineering, University of Sheffield**

Practical guide to profile machine learning code to find bottlenecks and to remove these bottlenecks.

<iframe id="kaltura_player" type="text/javascript"  src='https://cdnapisec.kaltura.com/p/2103181/embedPlaykitJs/uiconf_id/53345422?iframeembed=true&entry_id=1_zy2js5xq&config[provider]={"widgetId":"1_2ewj75mj"}&config[playback]={"startTime":0}'  style="width: 400px;height: 285px;border: 0;" allowfullscreen webkitallowfullscreen mozAllowFullScreen allow="autoplay *; fullscreen *; encrypted-media *" sandbox="allow-downloads allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation" title="How to make your machine learning code faster"></iframe>

- [Presentation slides](/assets/slides/2024-07-05-best-practices-ai/Profiling-ML-Code-with-Pytorch.pdf)
- [Code repository](https://github.com/EdwinB12/ProfileML)

### Nvidia Self-paced training courses and other ML resources
**<img class="align-self-center mr-2" src="/assets/images/icons/icons8-communication-skill-50.png" width="20" alt="Speaker"> Denis Battistella, Higher Education and Research, Nvidia**

<iframe id="kaltura_player" type="text/javascript"  src='https://cdnapisec.kaltura.com/p/2103181/embedPlaykitJs/uiconf_id/53345422?iframeembed=true&entry_id=1_e5azrc8x&config[provider]={"widgetId":"1_1lxy6j2c"}&config[playback]={"startTime":0}'  style="width: 400px;height: 285px;border: 0;" allowfullscreen webkitallowfullscreen mozAllowFullScreen allow="autoplay *; fullscreen *; encrypted-media *" sandbox="allow-downloads allow-forms allow-same-origin allow-scripts allow-top-navigation allow-pointer-lock allow-popups allow-modals allow-orientation-lock allow-popups-to-escape-sandbox allow-presentation allow-top-navigation-by-user-activation" title="Nvidia Self-paced Training Courses"></iframe>

Links to the resources discussed in the presentation:

- Training from Nvidia:
  - [Deep Learning Institute and Training Solutions](https://www.nvidia.com/en-gb/training/)
  - [Self-paced training courses](https://www.nvidia.com/en-gb/training/online/)
  - [Instructor-led workshops](https://learn.nvidia.com/en-us/training/instructor-led-workshops)
  - [DLI University Ambassador Program](https://www.nvidia.com/en-gb/training/educator-programs/university-ambassador-program/)
  - [Deep Learning Programs for Educators](https://www.nvidia.com/en-gb/training/educator-programs/)
  - Twin Karmakharm (<a href="t.karmakharm@sheffield.ac.uk">t.karmakharm@sheffield.ac.uk</a>) of the RSE group is the University of Sheffield's local DLI ambassador and can help with access to the above training resources.  
- PhD fellowships: [https://research.nvidia.com/graduate-fellowships#gf-section-graduate-fellows-](https://research.nvidia.com/graduate-fellowships#gf-section-graduate-fellows-)
- Accelerated software:
  - Denis touched upon [NGC](https://www.nvidia.com/en-us/gpu-cloud/): software repository for accelerated software, including SDKs, frameworks, containers – which you can download and deploy for free. Regularly updated.
  - New released [NIM](https://www.nvidia.com/en-gb/ai/) accelerated inference microservices to accelerate the deployment of Gen AI models.


### Acknowledgements 

We'd like to say thank you to all the speakers and attendees for making [Best Practices in AI Afternoon](/events/seminar-2024-07-05-best-practices-in-ai-afternoon) 
a great success! 

Thank you to Emma and Kate from the [Centre for Machine Intelligence (CMI)](https://www.sheffield.ac.uk/machine-intelligence) for all the help with 
organising the event and the [CMI](https://www.sheffield.ac.uk/machine-intelligence) and Nvidia for sponsoring the event.  


### Photos from the day

![Karin Sevegnani presenting](/assets/slides/2024-07-05-best-practices-ai/P1022846.jpg)
*Karin Sevegnani presenting "Maximizing Efficiency in Large Language Models: Compute, Memory, and Fine-Tuning"* 

![Ryan Daniels presenting](/assets/slides/2024-07-05-best-practices-ai/P1022853.jpg)
*Ryan Daniels presenting "Docker for Machine Learning"*

![Edwin Brown presenting](/assets/slides/2024-07-05-best-practices-ai/P1022858.jpg)
*Edwin Brown presenting "How to make your machine learning code faster"*

![Bob Turner presenting](/assets/slides/2024-07-05-best-practices-ai/P1022860.jpg)
*Bob Turner presenting "From Research Software to Software as a Service"*

![Denis Battistella presenting](/assets/slides/2024-07-05-best-practices-ai/P1022862.jpg)
*Denis Battistella presenting "Nvidia Self-paced Training Courses"*

![Q & A Panel](/assets/slides/2024-07-05-best-practices-ai/P1022863.jpg)
*Q & A Panel with Andy Grant, Edwin Brown, Ryan Daniels, and Christopher Wild*

